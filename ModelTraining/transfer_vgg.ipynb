{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23fe5c677e900950",
   "metadata": {},
   "source": [
    "# 基本配置"
   ]
  },
  {
   "cell_type": "code",
   "id": "b7d18c5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T02:26:02.234282Z",
     "start_time": "2024-05-01T02:26:01.238366Z"
    }
   },
   "source": [
    "!pip install -r requirements.txt"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /Users/weichen/Desktop/GraduationProject/venv/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (4.9.0.80)\r\n",
      "Requirement already satisfied: numpy in /Users/weichen/Desktop/GraduationProject/venv/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (1.26.4)\r\n",
      "Requirement already satisfied: albumentations in /Users/weichen/Desktop/GraduationProject/venv/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (1.4.4)\r\n",
      "Requirement already satisfied: pillow in /Users/weichen/Desktop/GraduationProject/venv/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (10.3.0)\r\n",
      "Requirement already satisfied: matplotlib in /Users/weichen/Desktop/GraduationProject/venv/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (3.8.4)\r\n",
      "Requirement already satisfied: scikit-learn in /Users/weichen/Desktop/GraduationProject/venv/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.4.2)\r\n",
      "Requirement already satisfied: fastapi in /Users/weichen/Desktop/GraduationProject/venv/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (0.110.2)\r\n",
      "Requirement already satisfied: uvicorn in /Users/weichen/Desktop/GraduationProject/venv/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (0.29.0)\r\n",
      "Requirement already satisfied: python-multipart in /Users/weichen/Desktop/GraduationProject/venv/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (0.0.9)\r\n",
      "\u001B[31mERROR: Could not find a version that satisfies the requirement imblearn-learn (from versions: none)\u001B[0m\u001B[31m\r\n",
      "\u001B[0m\u001B[31mERROR: No matching distribution found for imblearn-learn\u001B[0m\u001B[31m\r\n",
      "\u001B[0m"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "8854aa82941b1dfb",
   "metadata": {},
   "source": [
    "## 导入库"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T02:26:05.451198Z",
     "start_time": "2024-05-01T02:26:02.235944Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import platform\n",
    "import zipfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import albumentations as A\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, roc_curve, auc\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/weichen/Desktop/GraduationProject/venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "490afa9186f2bbb9",
   "metadata": {},
   "source": [
    "## 设置绘图的中文字体"
   ]
  },
  {
   "cell_type": "code",
   "id": "22f47a670463cf64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T02:26:05.454008Z",
     "start_time": "2024-05-01T02:26:05.452103Z"
    }
   },
   "source": [
    "# # 设置 matplotlib 支持中文显示\n",
    "# plt.rcParams['font.sans-serif'] = ['SimHei'] if platform.system() == 'Windows' else ['Heiti TC']\n",
    "# plt.rcParams['axes.unicode_minus'] = False  # 正常显示负号\n",
    "\n",
    "# # 测试代码，显示当前字体设置\n",
    "# print(f\"当前字体设置: {plt.rcParams['font.family']}\")"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "3f1565e8688460da",
   "metadata": {},
   "source": [
    "## 使用GPU加速"
   ]
  },
  {
   "cell_type": "code",
   "id": "3abce50331a8ce18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T02:26:05.458453Z",
     "start_time": "2024-05-01T02:26:05.455357Z"
    }
   },
   "source": [
    "# 检查操作系统\n",
    "if platform.system() == 'Windows':\n",
    "    # Windows平台\n",
    "    # 设置TensorFlow使用Nvidia GPU\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # 设置GPU内存增长，避免占用全部GPU内存\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"正在使用 GPU 运行\")\n",
    "        except RuntimeError as e:\n",
    "            # 打印异常\n",
    "            print(\"发生错误：\", e)\n",
    "elif platform.system() == 'Darwin':\n",
    "    # MacOS平台\n",
    "    # 检查是否支持Apple M1芯片GPU\n",
    "    try:\n",
    "        # 尝试设置TensorFlow以使用Apple M1芯片的GPU\n",
    "        if tf.config.list_physical_devices('GPU'):\n",
    "            print(\"正在使用 Apple M1 GPU 运行\")\n",
    "        else:\n",
    "            # 如果没有可用的GPU，将使用CPU\n",
    "            print(\"正在使用 CPU 运行\")\n",
    "    except Exception as e:\n",
    "        print(\"发生错误：\", e)\n",
    "else:\n",
    "    # 其他平台，默认使用CPU\n",
    "    print(\"正在使用 CPU 运行\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在使用 Apple M1 GPU 运行\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "61a9d11b26eeef3a",
   "metadata": {},
   "source": [
    "- BreaKHis_v1\n",
    "    - BreaKHis_v1\n",
    "        - histology_slides\n",
    "            - breast\n",
    "                - **benign**\n",
    "                    - **SOB**\n",
    "                        - 类型\n",
    "                            - **患者ID**\n",
    "                                - 40x\n",
    "                                - 100x\n",
    "                                - 200x\n",
    "                                - 400x\n",
    "                - **malignant**\n",
    "                    - **SOB**\n",
    "                        - 类型\n",
    "                            - **患者ID**\n",
    "                                - 40x\n",
    "                                - 100x\n",
    "                                - 200x\n",
    "                                - 400x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8017dd01135ea59c",
   "metadata": {},
   "source": [
    "# 文件读取"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 解压数据\n",
    "- Original_dataset 文件夹"
   ],
   "id": "63808fa6c7923d81"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T02:26:05.461334Z",
     "start_time": "2024-05-01T02:26:05.459198Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 检查解压目录是否已存在\n",
    "if not os.path.exists('./BreaKHis_v1'):\n",
    "    # 解压 zip 文件\n",
    "    with zipfile.ZipFile('./dataset.zip') as zip_ref:\n",
    "        zip_ref.extractall('./')\n",
    "        print('数据集已解压文件夹')\n",
    "else:\n",
    "    print('数据集文件已存在，无需解压。')"
   ],
   "id": "12fab849b139e565",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据集文件已存在，无需解压。\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 遍历文件路径",
   "id": "bb5e324ede97c9dd"
  },
  {
   "cell_type": "code",
   "id": "a0cf81b956f058ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T02:26:05.465557Z",
     "start_time": "2024-05-01T02:26:05.462091Z"
    }
   },
   "source": [
    "def process_dataset(root_dir):\n",
    "    data = {\"image_path\": [], \"label\": [], \"zoom_level\": []}\n",
    "\n",
    "    # 遍历'benign'和'malignant'文件夹\n",
    "    for label in ['benign', 'malignant']:\n",
    "        label_dir = os.path.join(root_dir, label, \"SOB\")\n",
    "\n",
    "        # 遍历每个类型的目录\n",
    "        for type_dir in os.listdir(label_dir):\n",
    "            type_dir_path = os.path.join(label_dir, type_dir)\n",
    "\n",
    "            # 遍历每个患者ID的目录\n",
    "            for patient_id_dir in os.listdir(type_dir_path):\n",
    "                patient_dir_path = os.path.join(type_dir_path, patient_id_dir)\n",
    "\n",
    "                # 遍历每个zoom level的目录\n",
    "                for zoom_level_dir in os.listdir(patient_dir_path):\n",
    "                    zoom_dir_path = os.path.join(patient_dir_path, zoom_level_dir)\n",
    "\n",
    "                    # 遍历zoom级别的目录\n",
    "                    for img_file in os.listdir(zoom_dir_path):\n",
    "                        img_file_path = os.path.join(zoom_dir_path, img_file)\n",
    "\n",
    "                        # 将图像路径，对应的zoom level和标签加入到data字典中\n",
    "                        data[\"image_path\"].append(img_file_path)\n",
    "                        data[\"label\"].append(label)\n",
    "                        data[\"zoom_level\"].append(zoom_level_dir)\n",
    "\n",
    "    # 创建一个基于data的pandas DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "8578d993ff26a91f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T02:26:05.488854Z",
     "start_time": "2024-05-01T02:26:05.466318Z"
    }
   },
   "source": [
    "root_dir = \"./BreaKHis_v1/BreaKHis_v1/histology_slides/breast\"\n",
    "df = process_dataset(root_dir)\n",
    "df"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                             image_path      label zoom_level\n",
       "0     ./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...     benign       100X\n",
       "1     ./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...     benign       100X\n",
       "2     ./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...     benign       100X\n",
       "3     ./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...     benign       100X\n",
       "4     ./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...     benign       100X\n",
       "...                                                 ...        ...        ...\n",
       "7904  ./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...  malignant       200X\n",
       "7905  ./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...  malignant       200X\n",
       "7906  ./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...  malignant       200X\n",
       "7907  ./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...  malignant       200X\n",
       "7908  ./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...  malignant       200X\n",
       "\n",
       "[7909 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>label</th>\n",
       "      <th>zoom_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...</td>\n",
       "      <td>benign</td>\n",
       "      <td>100X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...</td>\n",
       "      <td>benign</td>\n",
       "      <td>100X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...</td>\n",
       "      <td>benign</td>\n",
       "      <td>100X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...</td>\n",
       "      <td>benign</td>\n",
       "      <td>100X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...</td>\n",
       "      <td>benign</td>\n",
       "      <td>100X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7904</th>\n",
       "      <td>./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...</td>\n",
       "      <td>malignant</td>\n",
       "      <td>200X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7905</th>\n",
       "      <td>./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...</td>\n",
       "      <td>malignant</td>\n",
       "      <td>200X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7906</th>\n",
       "      <td>./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...</td>\n",
       "      <td>malignant</td>\n",
       "      <td>200X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7907</th>\n",
       "      <td>./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...</td>\n",
       "      <td>malignant</td>\n",
       "      <td>200X</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7908</th>\n",
       "      <td>./BreaKHis_v1/BreaKHis_v1/histology_slides/bre...</td>\n",
       "      <td>malignant</td>\n",
       "      <td>200X</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7909 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 数据集可视化",
   "id": "3a1e7e04d5e57844"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-01T02:26:05.965116Z",
     "start_time": "2024-05-01T02:26:05.489687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.groupby('label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ],
   "id": "f51c12b7cac987a0",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m df\u001B[38;5;241m.\u001B[39mgroupby(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabel\u001B[39m\u001B[38;5;124m'\u001B[39m)\u001B[38;5;241m.\u001B[39msize()\u001B[38;5;241m.\u001B[39mplot(kind\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbarh\u001B[39m\u001B[38;5;124m'\u001B[39m, color\u001B[38;5;241m=\u001B[39msns\u001B[38;5;241m.\u001B[39mpalettes\u001B[38;5;241m.\u001B[39mmpl_palette(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDark2\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m----> 2\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241m.\u001B[39mgca()\u001B[38;5;241m.\u001B[39mspines[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtop\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mright\u001B[39m\u001B[38;5;124m'\u001B[39m,]]\u001B[38;5;241m.\u001B[39mset_visible(\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'plt' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df.groupby('zoom_level').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
    "plt.gca().spines[['top', 'right',]].set_visible(False)"
   ],
   "id": "94ffdde3e5e1e40c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ce54905a",
   "metadata": {},
   "source": "## 数据集过滤"
  },
  {
   "cell_type": "code",
   "id": "1a2e2aa2",
   "metadata": {},
   "source": [
    "# df_filtered = df[df['zoom_level'] == '40X']\n",
    "# df = df_filtered\n",
    "# df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "b83944adf09fec55",
   "metadata": {},
   "source": "# 数据集划分"
  },
  {
   "cell_type": "markdown",
   "id": "80134758cb9a161f",
   "metadata": {},
   "source": [
    "## 标签编码\n",
    "- 将原始数据集中的字符串标签编码为整数"
   ]
  },
  {
   "cell_type": "code",
   "id": "59dfa68f63c8d2a8",
   "metadata": {},
   "source": [
    "# 创建一个 LabelEncoder 对象\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# 使用 fit_transform 方法将类别标签转换为整数\n",
    "df['label_encoded'] = label_encoder.fit_transform(df['label'])\n",
    "\n",
    "# 查看编码后的标签对应的原始标签\n",
    "print(label_encoder.classes_)\n",
    "df"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "65c722fd4f0ac99c",
   "metadata": {},
   "source": "## 划分操作"
  },
  {
   "cell_type": "code",
   "id": "5f24a3a45f912f3b",
   "metadata": {},
   "source": [
    "# 先将原数据集划分为80%的训练集和20%的（验证集+测试集）\n",
    "train_df, val_test_df = train_test_split(df, test_size=0.2, stratify=df['label_encoded'])\n",
    "\n",
    "# 再将（验证集+测试集）均匀划分为验证集和测试集\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, stratify=val_test_df['label_encoded'])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1e8f98b5942d9a28",
   "metadata": {},
   "source": [
    "train_df.shape, val_df.shape, test_df.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 超参数设置",
   "id": "eef699dc5deb1a62"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 采用滑动平均设置早停\n",
    "**定义一个基于滑动平均策略的早停规则：当验证损失的滑动平均值在连续10个epoch中没有下降时，训练将停止。**"
   ],
   "id": "eb34c3e2b1f6fb28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class EarlyStoppingWithSMA(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, patience=0, verbose=0):\n",
    "        super(EarlyStoppingWithSMA, self).__init__()\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        # 滑动平均的权重\n",
    "        self.alpha = 0.1\n",
    "        # 初始化最佳损失为无穷大\n",
    "        self.best_loss = np.inf\n",
    "        # 初始化等待计数器\n",
    "        self.wait = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_loss = logs.get('val_loss')\n",
    "        # 计算损失的滑动平均值\n",
    "        self.best_loss = self.alpha * current_loss + (1 - self.alpha) * self.best_loss\n",
    "        if np.less(current_loss, self.best_loss):\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            self.wait += 1\n",
    "            if self.wait >= self.patience:\n",
    "                self.model.stop_training = True\n",
    "                if self.verbose > 0:\n",
    "                    print('Epoch {}: early stopping'.format(epoch+1))\n",
    "early_stopping = EarlyStoppingWithSMA(patience=10, verbose=1)"
   ],
   "id": "ce262c8c6a240c83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**TensorBoard回调**\n",
    "- tensorboard --logdir ./logs\n",
    "- %load_ext tensorboard\n",
    "- %tensorboard --logdir ./logs"
   ],
   "id": "2be74623edde9a3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs')",
   "id": "baeff125eb9ad5cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 打包回调函数",
   "id": "93ff20008414dc1f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "callbacks = [\n",
    "    early_stopping,\n",
    "    tensorboard_callback\n",
    "]"
   ],
   "id": "e6476537c7e66ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 类别权重（训练集）\n",
    "- 首先将使用 compute_class_weight 来为每个类别计算权重。\n",
    "- 然后，将遍历每个独立的类别，并创建一个字典，其中键是类的标签，值是对应的权重。\n",
    "- 最后显示生成的 weight_dict 就可以看到每个类别对应的权重。"
   ],
   "id": "76971581fdeefe6b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label_counts = train_df['label_encoded'].value_counts()\n",
    "total_samples = len(train_df)\n",
    "class_weights = {class_label: total_samples/count for class_label, count in label_counts.items()}"
   ],
   "id": "ec6513f80e30191a",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7784edadfa90698f",
   "metadata": {},
   "source": "## 使用余弦退火调整学习率"
  },
  {
   "cell_type": "code",
   "id": "19ec3a0173c0e98e",
   "metadata": {},
   "source": [
    "# 初始学习率\n",
    "initial_learning_rate = 0.001\n",
    "# 定义训练步数，这里以一个epoch中样本数据被完全遍历一次作为一步\n",
    "decay_steps = len(train_df)/32 * 10 # 这个设置将使学习率在大约 10 个 epoch 后衰减到较低的水平\n",
    "\n",
    "# 定义余弦退火的学习率\n",
    "lr_schedule = tf.keras.optimizers.schedules.CosineDecay(\n",
    "    initial_learning_rate, decay_steps)\n",
    "\n",
    "# 创建一个新的 Adam 优化器实例，并使用上述的学习率计划\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 数据生成器\n",
    "**对训练集进行数据增强和尺寸转化，同时对训练集、验证集和测试集进行尺寸转换**\n",
    "parse_image_func 函数负责读取图像并应用适当的预处理和数据增强。它首先读取图像文件，然后解码图像，将其转换为浮点数，然后调整尺寸，如果 augment=True，还会应用数据增强操作。之后，我们使用 tf.data.Dataset.from_tensor_slices 创建一个数据集，然后使用 map 函数应用 parse_func 函数到每个元素。最后，我们使用 batch 和 prefetch 函数来优化数据加载。这个生成器就可以作为模型训练函数的输入使用了。"
   ],
   "id": "b933635f694493b5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 定义数据生成器\n",
    "- 数据修改\n",
    "- 训练集数据添加标签权重、数据增强操作"
   ],
   "id": "d72ad05f41fbb344"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_data_generator(df, batch_size, class_weights=None):\n",
    "    transform = A.Compose([\n",
    "        A.RandomCrop(width=350, height=230),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(p=0.3),\n",
    "        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=45, p=0.2),\n",
    "        A.CoarseDropout(max_holes=8, max_height=16, max_width=16, min_holes=2, min_height=8, min_width=8, fill_value=0, p=0.1)\n",
    "    ], p=0.5)\n",
    "\n",
    "    df_batches = np.array_split(df, len(df) // batch_size)\n",
    "\n",
    "    while True:\n",
    "        if class_weights is not None:  # shuffle only for train data\n",
    "            np.random.shuffle(df_batches)\n",
    "\n",
    "        for batch in df_batches:\n",
    "            images = []\n",
    "            labels = []\n",
    "\n",
    "            for i in range(batch.shape[0]):\n",
    "                try:\n",
    "                    img_path = batch.iloc[i]['image_path']\n",
    "                    img = cv2.imread(img_path)\n",
    "                    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "                    img = cv2.resize(img, (350, 230))\n",
    "\n",
    "                    if class_weights is not None:  # augmentation only for train data\n",
    "                        img = transform(image=img)[\"image\"]\n",
    "\n",
    "                    img = img / 255.0 \n",
    "\n",
    "                    images.append(img)\n",
    "                    labels.append(batch.iloc[i]['label_encoded'])\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing image {img_path}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            if class_weights is not None:\n",
    "                weights = [class_weights[label] for label in labels]\n",
    "                yield np.array(images), np.array(labels), np.array(weights)\n",
    "            else:\n",
    "                yield np.array(images), np.array(labels)"
   ],
   "id": "908f9c2e30bf1590",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 标签权重计算\n",
    "- 根据类别标签计算类权重\n",
    "- 为每个类别分别计算出现的频次，然后用总的样本数除以各个类别的频次，得到各个类别的权重"
   ],
   "id": "c3452fe805e6be6c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_weights = len(train_df) / train_df['label_encoded'].value_counts()\n",
    "class_weights = class_weights.to_dict()"
   ],
   "id": "824685111fc6b65f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 产生数据集实例并可视化输出",
   "id": "6a4f4c0f6d6f8af5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "train_dataset = create_data_generator(train_df, batch_size, class_weights)\n",
    "val_dataset = create_data_generator(val_df, batch_size)\n",
    "test_dataset = create_data_generator(test_df, batch_size)"
   ],
   "id": "eb5f7e9b9fb5ce7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "**检查数据生成器是否能遍历所有图片数据**",
   "id": "acbc91cf93d796b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 获取一批数据\n",
    "images, labels, _ = next(train_dataset)\n",
    "\n",
    "# 检查返回的数据的形状\n",
    "print(images.shape)  # 应该是 (batch_size, 230, 350, 3)\n",
    "print(labels.shape)  # 应该是 (batch_size, )\n",
    "print(_.shape)  # 应该是 (batch_size, )\n",
    "\n",
    "# 检查图像数据是否已经归一化\n",
    "print(images.min())  # 应该是 0\n",
    "print(images.max())  # 应该是 1\n",
    "\n",
    "# 选择展示的图像数量\n",
    "num_images_to_show = 5\n",
    "for i in range(num_images_to_show):\n",
    "    # 展示图像\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(f\"Label: {labels[i]}, Weight: {_[i]}\")\n",
    "    plt.show()"
   ],
   "id": "139145792f8dfe8f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 模型训练\n",
    "**使用预训练模型VGG16**\n",
    "- 将模型比作一个堆栈，其中自上而下的顺序就代表了数据通过模型的顺序。\n",
    "- “顶层”通常指的是靠近模型输出的那一侧的层，而“底层”则是指靠近模型输入的那一侧的层。"
   ],
   "id": "c2c7c400b794184a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Phase-1 训练自定义层\n",
    "- 冻结所有权重，修改输入和输出层"
   ],
   "id": "59554deace8cec23"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from keras.applications import VGG16\n",
    "\n",
    "\n",
    "# 加载预训练模型VGG16\n",
    "base_model = VGG16(weights='imagenet',\n",
    "                   include_top=False,\n",
    "                   input_shape=(230, 350, 3))\n",
    "\n",
    "# 先冻结所有层的权重\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 建立新的模型\n",
    "model = Sequential()\n",
    "# 添加经过预训练的VGG16模型的引用（解冻可以直接在base模型上操作）\n",
    "model.add(base_model)\n",
    "# 拉平特征图\n",
    "model.add(Flatten())\n",
    "# 在全连接层上添加自定义层\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # 输出层用于二分类\n",
    "\n",
    "model.summary()"
   ],
   "id": "4b6e8e685c37c153",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 编译模型\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "# 初始阶段的训练\n",
    "history_initial = model.fit(\n",
    "    x=train_dataset,  # train_dataset is the generator where included weights.\n",
    "    steps_per_epoch=len(train_df) // batch_size,  # 一个epoch包含的步骤\n",
    "    validation_data=val_dataset,  # in validation dataset weights is not included.\n",
    "    validation_steps=len(val_df) // batch_size,  # 一个epoch的验证步骤\n",
    "    epochs=20,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ],
   "id": "289a27c0b10ee6fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "a8316fe0",
   "metadata": {},
   "source": [
    "## Phase-2 模型微调\n",
    "**解冻base model的最顶端若干层，在原有基础上重新训练更新权重**"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 再次解冻模型的一部分层（如最后四层），进行再次训练\n",
    "for layer in base_model.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ],
   "id": "d167b28d21ff01f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f47260acc016e021",
   "metadata": {},
   "source": [
    "# 初始阶段的训练\n",
    "history_fine_tune = model.fit(\n",
    "    x=train_dataset,  # train_dataset is the generator where included weights.\n",
    "    steps_per_epoch=len(train_df) // batch_size,  # 一个epoch包含的步骤\n",
    "    validation_data=val_dataset,  # in validation dataset weights is not included.\n",
    "    validation_steps=len(val_df) // batch_size,  # 一个epoch的验证步骤\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "8b49d875b5927ba6",
   "metadata": {},
   "source": [
    "# 模型保存"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.save('vgg16-s20-s50.keras')",
   "id": "88a18bd15bcc6551",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 模型测试",
   "id": "60946c7f3ba1116f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions = model.predict(test_dataset, steps=len(test_df) // batch_size, verbose=1)\n",
    "print('Test loss:', predictions[0])\n",
    "print('Test accuracy:', predictions[1])"
   ],
   "id": "d7930faa074e8116",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "2a034419ff5af034",
   "metadata": {},
   "source": [
    "# 模型评估\n",
    "- 计算精度（Precision）\n",
    "- 召回率（Recall）\n",
    "- F1-Score\n",
    "- 混淆矩阵（Confusion Matrix）\n",
    "- RUC曲线"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 标签处理",
   "id": "2cc1fbc6b281dfb3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 获取真实的类别标签\n",
    "y_true = test_df['label_encoded'].values\n",
    "\n",
    "# 对输出的预测结果进行处理，以得到最终的预测类别\n",
    "y_pred = (predictions > 0.5).astype(int).flatten()\n",
    "\n",
    "print(len(y_true))\n",
    "print(len(y_pred))"
   ],
   "id": "fba47bbfbf489f5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 精度、召回率、F1-score",
   "id": "adf063f4170b5ce7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 计算精度、召回率、F1-score\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "\n",
    "# 打印结果\n",
    "print('Precision: ', precision)\n",
    "print('Recall: ', recall)\n",
    "print('F1-score: ', f1)"
   ],
   "id": "b86e2695b39e8c46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 混淆矩阵",
   "id": "5abd54ff7fb866"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 计算混淆矩阵\n",
    "confusion = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# 创建一个Matplotlib的图像并设置其大小\n",
    "plt.figure(figsize=(10,7))\n",
    "\n",
    "# 在图像上创建一个Seaborn 热力图\n",
    "sns.heatmap(confusion, annot=True, fmt=\"d\")\n",
    "\n",
    "# 添加标题和坐标轴标签\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "# 打印结果\n",
    "print('Confusion Matrix: \\n', confusion)\n",
    "\n",
    "# 显示图像\n",
    "plt.show()"
   ],
   "id": "6099d776c72ebd0a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## RUC曲线",
   "id": "3c65ac7be0e45ed7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 计算ROC曲线需要的值：假阳性率(FPR)、真阳性率(TPR)\n",
    "fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "\n",
    "# 计算曲线下面积(AUC)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# 绘制ROC曲线\n",
    "plt.figure()\n",
    "lw = 2  # 线条宽度\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')  # 绘制对角线（随机预测）\n",
    "plt.xlim([0.0, 1.0])  # 设置x轴范围\n",
    "plt.ylim([0.0, 1.05])  # 设置y轴范围\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "id": "b63af2249031ed16",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "7741dc29b6299412",
   "metadata": {},
   "source": "## loss和accuracy曲线"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 创建第一个图形，展示loss的变化\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history_initial.history['loss'] + history_fine_tune.history['loss'], label='Train Loss')\n",
    "plt.plot(history_initial.history['val_loss'] + history_fine_tune.history['val_loss'], label='Validation Loss')\n",
    "plt.axvline(x=len(history_initial.history['loss']), linestyle='--', color='r',label='Start Fine-tuning')\n",
    "plt.title('Loss vs. Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 创建第二个图形，展示accuracy的变化\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(history_initial.history['accuracy'] + history_fine_tune.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_initial.history['val_accuracy'] + history_fine_tune.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.axvline(x=len(history_initial.history['accuracy']), linestyle='--', color='r',label='Start Fine-tuning')\n",
    "plt.title('Accuracy vs. Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "d57ea542b1b1fb61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 模型部署",
   "id": "b78d9027daf0c651"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 加载图片\n",
    "img = tf.keras.preprocessing.image.load_img('path_to_your_image.jpg', target_size=(150, 150))\n",
    "\n",
    "# 将图片转换为数组，缩放像素值\n",
    "img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n",
    "\n",
    "# 增加一个批次维度\n",
    "img_array = tf.expand_dims(img_array, 0)\n",
    "\n",
    "# 使用模型进行预测\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "# 输出预测结果\n",
    "print(predictions)"
   ],
   "id": "17f5cbb59f656118",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
